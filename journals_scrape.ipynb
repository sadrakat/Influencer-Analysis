{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TSrnFwkoD9w",
        "outputId": "86cfab96-4aba-4d8e-f4dd-d0382dc8ff63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBdLzcdBnsw_",
        "outputId": "d4634e50-4507-46ee-b2bd-771446d581a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracting content from: Is Coffee Harmful? If Looking for Longevity, Say Yes to the Coffee, No to the Sugar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 500, but your input_length is only 334. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=167)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarizing the extracted content...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 500, but your input_length is only 338. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=169)\n",
            "Your max_length is set to 500, but your input_length is only 352. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=176)\n",
            "Your max_length is set to 500, but your input_length is only 291. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=145)\n",
            "Your max_length is set to 500, but your input_length is only 320. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=160)\n",
            "Your max_length is set to 500, but your input_length is only 313. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=156)\n",
            "Your max_length is set to 500, but your input_length is only 358. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=179)\n",
            "Your max_length is set to 500, but your input_length is only 305. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=152)\n",
            "Your max_length is set to 500, but your input_length is only 263. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=131)\n",
            "Your max_length is set to 500, but your input_length is only 279. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=139)\n",
            "Your max_length is set to 500, but your input_length is only 318. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=159)\n",
            "Your max_length is set to 500, but your input_length is only 113. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=56)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to /content/journal_insights.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pdfplumber\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load NLP model for text processing (spaCy)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Initialize the summarization pipeline using Hugging Face Transformers\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Function to extract content from the PDF file\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        text = \"\"\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text()  # Extracts text from each page\n",
        "    return text\n",
        "\n",
        "# Function to summarize the content in manageable chunks\n",
        "def summarize_large_content(content, chunk_size=1000):\n",
        "    # Split content into chunks of chunk_size\n",
        "    chunks = [content[i:i + chunk_size] for i in range(0, len(content), chunk_size)]\n",
        "\n",
        "    summaries = []\n",
        "    for chunk in chunks:\n",
        "        try:\n",
        "            # Summarize each chunk\n",
        "            summary = summarizer(chunk, max_length=500, min_length=100, do_sample=False)\n",
        "            summaries.append(summary[0]['summary_text'])\n",
        "        except Exception as e:\n",
        "            print(f\"Error summarizing chunk: {e}\")\n",
        "            summaries.append(chunk)  # If error, append the original chunk\n",
        "\n",
        "    # Combine all summaries into one\n",
        "    full_summary = \" \".join(summaries)\n",
        "    return full_summary\n",
        "\n",
        "# Function to load data into a structured format (e.g., CSV)\n",
        "def load_to_csv(data, filename=\"journal_insights.csv\"):\n",
        "    current_directory = os.getcwd()  # Get the current working directory\n",
        "    full_path = os.path.join(current_directory, filename)\n",
        "\n",
        "    df = pd.DataFrame(data, columns=[\"Title\", \"PDF_Path\", \"Summary\"])\n",
        "    df.to_csv(full_path, index=False)\n",
        "\n",
        "    print(f\"Data saved to {full_path}\")  # Print the full path\n",
        "\n",
        "# Main ETL Process\n",
        "def etl_pipeline(pdf_path, title):\n",
        "    print(f\"\\nExtracting content from: {title}\")\n",
        "\n",
        "    # Extract full content from PDF\n",
        "    content = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    if content:\n",
        "        print(\"Summarizing the extracted content...\")\n",
        "\n",
        "        # Summarize the content (handling large text)\n",
        "        summary = summarize_large_content(content)\n",
        "\n",
        "        # Load data to CSV\n",
        "        load_to_csv([[title, pdf_path, summary]])\n",
        "\n",
        "# Path to the PDF file\n",
        "pdf_path = \"/content/coffee.pdf\"  # Replace with your PDF file path\n",
        "pdf_title = \"Is Coffee Harmful? If Looking for Longevity, Say Yes to the Coffee, No to the Sugar\"  # Set the appropriate title\n",
        "\n",
        "# Run ETL pipeline\n",
        "etl_pipeline(pdf_path, pdf_title)\n"
      ]
    }
  ]
}